{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[PyCUDA](https://mathema.tician.de/software/pycuda/) is a Python wrapper around CUDA, NVidia's extension of C/C++ for GPUs.\n",
    "\n",
    "There's also a [PyOpenCL](https://mathema.tician.de/software/pyopencl/) for the vendor-independent OpenCL standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as driver\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# compute a MILLION values\n",
    "PROBLEM_SIZE = int(1e6)\n",
    "\n",
    "# generate a CUDA (C-ish) function that will run on the GPU; PROBLEM_SIZE is hard-wired\n",
    "module = SourceModule(\"\"\"\n",
    "__global__ void just_multiply(float *dest, float *a, float *b)\n",
    "{\n",
    "  // function is called for ONE item; find out which one\n",
    "  const int id = threadIdx.x + blockDim.x*blockIdx.x;\n",
    "  if (id < %d)\n",
    "    dest[id] = a[id] * b[id];\n",
    "}\n",
    "\"\"\" % PROBLEM_SIZE)\n",
    "\n",
    "# pull \"just_multiply\" out as a Python callable\n",
    "just_multiply = module.get_function(\"just_multiply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# create Numpy arrays on the CPU\n",
    "a = numpy.random.randn(PROBLEM_SIZE).astype(numpy.float32)\n",
    "b = numpy.random.randn(PROBLEM_SIZE).astype(numpy.float32)\n",
    "dest = numpy.zeros_like(a)\n",
    "\n",
    "# define block/grid size for our problem: at least 512 threads at a time (might do more)\n",
    "# and we're only going to use x indexes (the y and z sizes are 1)\n",
    "blockdim = (512, 1, 1)\n",
    "griddim = (int(math.ceil(PROBLEM_SIZE / 512.0)), 1, 1)\n",
    "\n",
    "# copy the \"driver.In\" arrays to the GPU, run the \n",
    "just_multiply(driver.Out(dest), driver.In(a), driver.In(b), block=blockdim, grid=griddim)\n",
    "\n",
    "# compare the GPU calculation (dest) with a CPU calculation (a*b)\n",
    "print dest - a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's do that calculation of $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "module2 = SourceModule(\"\"\"\n",
    "__global__ void mapper(float *dest)\n",
    "{\n",
    "  const int id = threadIdx.x + blockDim.x*blockIdx.x;\n",
    "  const double x = 1.0 * id / %d;     // x goes from 0.0 to 1.0 in PROBLEM_SIZE steps\n",
    "  if (id < %d)\n",
    "    dest[id] = 4.0 / (1.0 + x*x);\n",
    "}\n",
    "\"\"\" % (PROBLEM_SIZE, PROBLEM_SIZE))\n",
    "\n",
    "mapper = module2.get_function(\"mapper\")\n",
    "dest = numpy.empty(PROBLEM_SIZE, dtype=numpy.float32)\n",
    "blockdim = (512, 1, 1)\n",
    "griddim = (int(math.ceil(PROBLEM_SIZE / 512.0)), 1, 1)\n",
    "\n",
    "mapper(driver.Out(dest), block=blockdim, grid=griddim)\n",
    "\n",
    "dest.sum() * (1.0 / PROBLEM_SIZE)  # correct for bin size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We're doing the mapper (problem of size 1 million) on the GPU and the final sum (problem of size 1 million) on the CPU.\n",
    "\n",
    "However, we want to do all the big data work on the GPU.\n",
    "\n",
    "On the next slide is an algorithm that merges array elements with their neighbors in $\\log_2(\\mbox{million}) = 20$ steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "module3 = SourceModule(\"\"\"\n",
    "__global__ void reducer(float *dest, int i)\n",
    "{\n",
    "  const int PROBLEM_SIZE = %d;\n",
    "  const int id = threadIdx.x + blockDim.x*blockIdx.x;\n",
    "  if (id %% (2*i) == 0  &&  id + i < PROBLEM_SIZE) {\n",
    "    dest[id] += dest[id + i];\n",
    "  }\n",
    "}\n",
    "\"\"\" % PROBLEM_SIZE)\n",
    "\n",
    "blockdim = (512, 1, 1)\n",
    "griddim = (int(math.ceil(PROBLEM_SIZE / 512.0)), 1, 1)\n",
    "\n",
    "reducer = module3.get_function(\"reducer\")\n",
    "\n",
    "# Python for loop over the 20 steps to reduce the array\n",
    "i = 1\n",
    "while i < PROBLEM_SIZE:\n",
    "    reducer(driver.InOut(dest), numpy.int32(i), block=blockdim, grid=griddim)\n",
    "    i *= 2\n",
    "\n",
    "# final result is in the first element\n",
    "dest[0] * (1.0 / PROBLEM_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The only problem now is that we're copying this `dest` array back and forth between the CPU and GPU. Let's fix that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# allocate the array directly on the GPU, no CPU involved\n",
    "dest_gpu = driver.mem_alloc(PROBLEM_SIZE * numpy.dtype(numpy.float32).itemsize)\n",
    "\n",
    "# do it again without \"driver.InOut\", which copies Numpy (CPU) to and from the GPU\n",
    "mapper(dest_gpu, block=blockdim, grid=griddim)\n",
    "i = 1\n",
    "while i < PROBLEM_SIZE:\n",
    "    reducer(dest_gpu, numpy.int32(i), block=blockdim, grid=griddim)\n",
    "    i *= 2\n",
    "\n",
    "# we only need the first element, so create a Numpy array with exactly one element\n",
    "only_one_element = numpy.empty(1, dtype=numpy.float32)\n",
    "\n",
    "# copy just that one element\n",
    "driver.memcpy_dtoh(only_one_element, dest_gpu)\n",
    "\n",
    "print only_one_element[0] * (1.0 / PROBLEM_SIZE)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
